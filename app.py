import os
import re
import pandas as pd
import sysÂ 
import randomÂ 
import jsonÂ 
from openai import OpenAI
from typing import Literal
import streamlit as stÂ 
import httpx # ðŸ‘ˆ 1. ADDED: Required for custom timeout configuration

# ======================================================================
# 1. ENVIRONMENT AND API CONFIGURATION
# ======================================================================

# Using the user-specified model
MODEL_ID = "deepseek/deepseek-r1-0528:free"

# The global client will be initialized in run_streamlit_appÂ 
client: OpenAI = NoneÂ 

# ======================================================================
# 2. CONSTANTS AND DATA MAPPING
# ======================================================================

PLANT_SEQUENCE = [
Â  Â  'cacao', 'tea', 'mate', 'lemon', 'cardamom',Â 
Â  Â  'ginger', 'black pepper', 'osmanthus', 'frankincense', 'bay leaf'
]
VOICE_OPTIONS = ['elder', 'child', 'evidence']Â 
VOICE_MAPPING = {
Â  Â  'elder': 'Elder Herbalist',Â 
Â  Â  'child': 'Child Herbalist',Â 
Â  Â  'evidence': 'Evidence-Based Herbalist'
}

# The document content (omitted for brevity, assume it is unchanged from previous versions)
DOC_TEXT = """
---
1. Cacao
Latin Name: Theobroma cacao
Native Region: Central and South America
Plant Part Used: Seed (commonly called the â€œbeanâ€); fruit pulp occasionally used
Contraindications: Contains caffeine and theobromine; may not be suitable for people with caffeine sensitivity or certain heart conditions
Elder Herbalist: A sacred plant of the heart. The cacao bean is not just a treat, it is a ceremonyâ€”used to uplift mood and spirit, energize the body, and connect with others. The pulp surrounding the bean is also nourishing, though less commonly used.
Child Herbalist: Cacao is what chocolate is made from! Itâ€™s a bean from a fruit and has a yummy smell and taste. Sometimes itâ€™s made into sweet drinks or even used in special ceremonies.
Evidence-Based Herbalist: Contains theobromine and flavonoids that may support mood, circulation, and cardiovascular health. Also a source of magnesium and antioxidants. May mildly increase blood pressure or heart rate.
---
2. Tea (Camellia)
Latin Name: Camellia sinensis
Native Region: East Asia
Plant Part Used: Leaves and buds
Contraindications: Contains caffeine; may interfere with iron absorption; should be used with caution in pregnancy or insomnia
Elder Herbalist: A leaf of clarity and peace. Depending on how it is processed, tea may be light and uplifting (green), grounding (black), or mellow (white). When used externally, it cools and clears skin eruptions.
Child Herbalist: Tea leaves can make green or brown drinks, depending on how how theyâ€™re made. Green tea can help your skin feel calm, and tea helps you stay awake during the day!
Evidence-Based Herbalist: Contains caffeine, theanine, and catechins like EGCG. Green tea is antioxidant-rich and may support cardiovascular, metabolic, and cognitive health. Topical application has shown anti-inflammatory effects.
---
3. Yerba MatÃ©
Latin Name: Ilex paraguariensis
Native Region: South America (especially Argentina, Paraguay, and Brazil)
Plant Part Used: Leaves
Contraindications: Contains caffeine-like compounds; avoid excessive use in individuals with anxiety, insomnia, or high blood pressure
Elder Herbalist: This smoky, bitter leaf is revered for endurance and energy. It awakens the mind while providing nutrients to the blood. Traditionally shared in community through the gourd and bombilla.
Child Herbalist: MatÃ© is like a super strong tea that people in South America love. It helps you feel awake and strong, and they drink it with a special straw.
Evidence-Based Herbalist: Contains caffeine, theobromine, and antioxidants. Shown to improve alertness and may have cholesterol-lowering effects. Overuse may increase cancer risk when consumed at high temperatures over time.
---
4. Lemon
Latin Name: Citrus limon
Native Region: Asia (likely India and China)
Plant Part Used: Fruit (juice and peel), leaves occasionally
Contraindications: Acidic; may aggravate ulcers or sensitive stomachs in excess
Elder Herbalist: Bright and purifying, lemon clears dampness and stimulates digestion. The peel is aromatic and warming, while the juice refreshes and detoxifies.
Child Herbalist: Lemons are super sour fruits that make lemonade! Theyâ€™re also great for cleaning and have lots of vitamin C to help keep you healthy.
Evidence-Based Herbalist: Rich in vitamin C, citric acid, and flavonoids like hesperidin and quercetin. Shown to support immunity and digestion. Peel oil contains limonene with antimicrobial properties.
---
5. Cardamom
Latin Name: Elettaria cardamomum
Native Region: Southern India
Plant Part Used: Seed pods (and seeds inside)
Contraindications: Generally safe in culinary doses; avoid concentrated use in gallstone conditions
Elder Herbalist: Warming and harmonizing, cardamom moves stagnant food and awakens the Spleen Qi. Often used to balance heavy foods and settle the stomach.
Child Herbalist: Cardamom smells sweet and spicy! It helps with tummy aches and makes your food smell super good, especially in chai tea.
Evidence-Based Herbalist: Used to reduce bloating, gas, and support digestive enzymes. Contains essential oils (cineole, terpinyl acetate) with antimicrobial and anti-inflammatory activity.
---
6. Ginger
Latin Name: Zingiber officinale
Native Region: Southeast Asia
Plant Part Used: Rhizome (root)Â 
Contraindications: May interact with blood-thinning medications. Use with caution in those with gallstones.
Elder Herbalist: Ginger is a revered warming root, used to kindle the digestive fire and dispel internal cold. We use it fresh for surface conditions, such as colds and chills, and dried when deeper warmth is needed. It invigorates the blood and aids in moving stagnant Qi.
Child Herbalist: Ginger is like a spicy superhero root! It helps your tummy feel better when it's upset or if you're feeling carsick. Some people even drink ginger tea to help them feel warm and cozy when they're cold.
Evidence-Based Herbalist: Ginger has been shown to be effective in reducing nausea from motion sickness and pregnancy. It exhibits anti-inflammatory properties and may assist in reducing joint pain. Research suggests benefits for gastrointestinal motility and digestion.
---
7. Black Pepper
Latin Name: Piper nigrum
Native Region: South India
Plant Part Used: Dried unripe fruit (peppercorn)Â 
Contraindications: Generally safe in food amounts. Large quantities may irritate gastrointestinal tract.
Elder Herbalist: A pungent spice used to awaken the senses and open the channels. It can be combined with herbs like turmeric to enhance absorption and move internal cold.
Child Herbalist: Black pepper is the spicy specks you see on food! It adds flavor and can help your body stay warm. A little goes a long way!
Evidence-Based Herbalist: Piperine, the active compound in black pepper, increases the bioavailability of nutrients such as curcumin. It is used in formulations for digestion and metabolic support.
---
8. Osmanthus
Latin Name: Osmanthus fragrans
Native Region: China and the Himalayas
Plant Part Used: FlowerÂ 
Contraindications: No known major contraindications; generally used in culinary amounts.
Elder Herbalist: Fragrant flower of the autumn season, Osmanthus uplifts the spirit and soothes the heart. In traditional practice, it is used to harmonize the stomach and promote joy.
Child Herbalist: Osmanthus smells like happiness in a flower! Some teas and treats are made with it, and it's like natureâ€™s perfume.
Evidence-Based Herbalist: Osmanthus fragrans has been found to contain essential oils with potential antioxidant and mild sedative effects. It is primarily used for its fragrance in teas and confections.
---
9. Frankincense
Latin Name: Boswellia serrata (or Boswellia sacra, depending on species)
Native Region: Middle East and Northern Africa
Plant Part Used: ResinÂ 
Contraindications: May interact with anti-inflammatory medications. Avoid during pregnancy unless supervised.
Elder Herbalist: Sacred resin brought by wise ones. Used in ceremonies and for healing the pain of the joints. Often combined with myrrh for deeper blood-moving effect.
Child Herbalist: Frankincense is a shiny golden sap that smells really nice. People used it a long time ago in special ceremonies, and even now it's used in oils to help sore spots feel better.
Evidence-Based Herbalist: Boswellia resin contains boswellic acids, which have demonstrated anti-inflammatory effects in osteoarthritis and other inflammatory conditions. Used topically and internally in some traditional systems.
---
10. Bay Leaf
Latin Name: Laurus nobilis
Native Region: Mediterranean region
Plant Part Used: LeafÂ 
Contraindications: Generally safe in culinary amounts. Large doses may cause drowsiness or affect blood sugar.
Elder Herbalist: A gentle leaf added to broths and stews to harmonize the flavors and aid digestion. Also used in warming salves for the joints.
Child Herbalist: Bay leaf is like a magic flavor leaf! It doesnâ€™t taste good by itself, but when you cook it in soup or sauce, it makes everything taste better.
Evidence-Based Herbalist: Bay leaf (Laurus nobilis) contains essential oils and flavonoids. Some research supports mild antimicrobial and anti-inflammatory properties. Commonly used in culinary medicine to support digestion.
"""Â 

# ======================================================================
# 3. DATA LOADING & PARSING
# ======================================================================

def load_and_structure_plant_data(doc_text: str, sequence: list, voice_map: dict) -> pd.DataFrame:
Â  Â  """Parses the text, extracts details, and creates a DataFrame with one row per plant/voice combination."""
Â  Â Â 
Â  Â  plant_blocks = re.split(r'\n---\n\s*\d+\.\s', doc_text)[1:]Â 
Â  Â  data_list = []

Â  Â  try:
Â  Â  Â  Â  for block in plant_blocks:
Â  Â  Â  Â  Â  Â  lines = block.strip().split('\n')
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  plant_name_line = lines[0].split('(')[0].strip().lower()
Â  Â  Â  Â  Â  Â  plant_name = next((p for p in sequence if p in plant_name_line), plant_name_line.split(' ')[0])
Â  Â  Â  Â  Â  Â  if plant_name == 'yerba': plant_name = 'mate'Â 
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Extract fixed info
Â  Â  Â  Â  Â  Â  info = {line.split(':')[0].strip(): line.split(':')[-1].strip()Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for line in lines if ':' in line and not line.startswith(tuple(voice_map.values()))}

Â  Â  Â  Â  Â  Â  # Extract specific notes for each voice
Â  Â  Â  Â  Â  Â  for short_voice, long_voice in voice_map.items():
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  note_start_index = next(i for i, line in enumerate(lines) if line.startswith(long_voice))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  single_note = lines[note_start_index].split(':', 1)[-1].strip()
Â  Â  Â  Â  Â  Â  Â  Â  except StopIteration:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  single_note = "ERROR: Note not found in document."

Â  Â  Â  Â  Â  Â  Â  Â  # Store one row for each (plant, voice) combination
Â  Â  Â  Â  Â  Â  Â  Â  data_list.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'plant': plant_name,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'voice': short_voice,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'note': single_note, # This is the short note we'll expand
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'latin_name': info.get('Latin Name', 'N/A'),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'origin': info.get('Native Region', 'N/A'),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'parts_used': info.get('Plant Part Used', 'N/A'),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'contraindications': info.get('Contraindications', 'None known'),
Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  return pd.DataFrame(data_list)
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"\n[CRITICAL ERROR] Failed to load plant data. Check DOC_TEXT structure.")
Â  Â  Â  Â  print(f"Details: {e}")
Â  Â  Â  Â  sys.exit(1)


# ======================================================================
# 4. AGENT CLASS (LOGIC & FLOW)
# ======================================================================

class BotanicalGuideAgent:
Â  Â Â 
Â  Â  def __init__(self, plant_data: pd.DataFrame, sequence: list, voice_options: list):
Â  Â  Â  Â  self.plant_data = plant_data
Â  Â  Â  Â  self.plant_sequence = sequence
Â  Â  Â  Â  self.voice_options = voice_options
Â  Â  Â  Â Â 
Â  Â  Â  Â  # State Tracking
Â  Â  Â  Â  self.current_voice = NoneÂ 
Â  Â  Â  Â  self.current_plant = sequence[0]
Â  Â  Â  Â  self.current_plant_index = 0
Â  Â  Â  Â Â 
Â  Â  Â  Â  # State Tracking for reading parts
Â  Â  Â  Â  self.current_reading_step = 0Â 
Â  Â  Â  Â  self.expanded_readings: list[str] = []Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  self.REDIRECT_RESPONSES = [
Â  Â  Â  Â  Â  Â  "Interesting thought! These plants adapt in their own ways too. Let's return to {plant}.",
Â  Â  Â  Â  Â  Â  "Ha, that's a good one. Speaking of growth, {plant} has its own storyâ€¦",
Â  Â  Â  Â  Â  Â  "Noted. Our tour is focused on the plantsâ€”here's more about {plant}."
Â  Â  Â  Â  ]
Â  Â  Â  Â Â 
Â  Â  def _build_system_prompt(self, current_plant_row, user_input: str) -> str:
Â  Â  Â  Â  """
Â  Â  Â  Â  Builds the system prompt to enforce a structured prose output (Part 1, Part 2, Part 3)Â 
Â  Â  Â  Â  and guides the LLM on how to handle the user's input while maintaining guardrails.
Â  Â  Â  Â  """
Â  Â  Â  Â Â 
Â  Â  Â  Â  plant_name = current_plant_row['plant'].capitalize()
Â  Â  Â  Â  target_voice = current_plant_row['voice']
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Format the core instruction and data
Â  Â  Â  Â  prompt = (
Â  Â  Â  Â  Â  Â  f"You are a Botanical Garden Tour Guide for the plant **{plant_name}**. "
Â  Â  Â  Â  Â  Â  f"Your persona is the **{target_voice.upper()}** herbalist. "
Â  Â  Â  Â  Â  Â  f"Your role is to deliver a three-part scripted reading based on your 'notecards'. "
Â  Â  Â  Â  Â  Â  f"Your sole purpose is to provide structured information on the current plant.\n\n"
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  f"DATA:\n"
Â  Â  Â  Â  Â  Â  f"Latin Name: {current_plant_row['latin_name']}\n"
Â  Â  Â  Â  Â  Â  f"Region: {current_plant_row['origin']}\n"
Â  Â  Â  Â  Â  Â  f"Parts Used: {current_plant_row['parts_used']}\n"
Â  Â  Â  Â  Â  Â  f"Contraindications: {current_plant_row['contraindications']}\n"
Â  Â  Â  Â  Â  Â  f"Short Note: {current_plant_row['note']}\n\n"
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  f"USER INPUT: '{user_input}'\n\n"
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  f"INSTRUCTIONS:\n"
Â  Â  Â  Â  Â  Â  f"1. **Primary Guardrail:** Your response MUST stay focused on the plant. If the USER INPUT is off-topic (e.g., about movies, weather, or pricing), give a very brief, gentle acknowledgment, and immediately proceed to the structured reading.\n"
Â  Â  Â  Â  Â  Â  f"2. **Flow Control:** If the USER INPUT contains commands related to state change (like 'next plant', 'ginger', or another 'voice'), **ignore those commands** as the main application handles navigation. Only focus on interpreting general questions.\n"
Â  Â  Â  Â  Â  Â  f"3. **Your response MUST follow this exact, labeled structure** and contain ONLY the three parts of the reading:\n"
Â  Â  Â  Â  Â  Â  f"Â  Â - **Part 1: History and Origin**\n"
Â  Â  Â  Â  Â  Â  f"Â  Â - **Part 2: Key Features and Uses**\n"
Â  Â  Â  Â  Â  Â  f"Â  Â - **Part 3: Scientific Details and Context**\n"
Â  Â  Â  Â  Â  Â  f"4. **Do not include any other text** (no ending summary, no markdown wrappers)."
Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  return prompt

Â  Â  def _get_expanded_reading(self, user_input: str) -> tuple[str, dict]:
Â  Â  Â  Â  """
Â  Â  Â  Â  Collects data, sends the prompt, and splits the LLM's prose responseÂ 
Â  Â  Â  Â  into three parts based on the labeled structure.
Â  Â  Â  Â  """
Â  Â  Â  Â Â 
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  plant_row = self.plant_data[
Â  Â  Â  Â  Â  Â  Â  Â  (self.plant_data['plant'] == self.current_plant) &
Â  Â  Â  Â  Â  Â  Â  Â  (self.plant_data['voice'] == self.current_voice)
Â  Â  Â  Â  Â  Â  ].iloc[0]
Â  Â  Â  Â  except IndexError:
Â  Â  Â  Â  Â  Â  return "Error: Plant data not found for the current plant and voice.", {}

Â  Â  Â  Â  # 1. Generate the LLM System Prompt with the user's raw input
Â  Â  Â  Â  system_prompt = self._build_system_prompt(plant_row, user_input)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 2. Call the LLM to generate the structured readings (raw prose string)
Â  Â  Â  Â  prose_string_raw = generate_llm_response(system_prompt)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # --- ROBUST PROSE PARSING FIX ---
Â  Â  Â  Â  # Look for the predefined Part labels to split the response
Â  Â  Â  Â  parts = re.split(r'\*\*Part \d+: .*?\*\*', prose_string_raw.strip(), re.DOTALL)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Fallback list for error cases
Â  Â  Â  Â  self.expanded_readings = []
Â  Â  Â  Â  reading_text = ""
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Check if the split produced the expected number of sectionsÂ 
Â  Â  Â  Â  if len(parts) >= 4:
Â  Â  Â  Â  Â  Â  # Store the three main parts (indices 1, 2, 3)
Â  Â  Â  Â  Â  Â  self.expanded_readings = [p.strip() for p in parts[1:4]]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if self.expanded_readings[0]:
Â  Â  Â  Â  Â  Â  Â  Â  reading_text = self.expanded_readings[0] # Part 1 content
Â  Â  Â  Â  Â  Â  Â  Â  self.current_reading_step = 1 # Set to start at the first reading
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â reading_text = f"[LLM STRUCTURE ERROR] The guide generated structure but Part 1 was empty. Raw output begins: {prose_string_raw[:200]}..."
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # The model failed to adhere to the Part structure, or returned an error/empty content
Â  Â  Â  Â  Â  Â  reading_text = f"[LLM STRUCTURE ERROR] The guide failed to generate the reading correctly. Raw output begins: {prose_string_raw[:200]}..."

Â  Â  Â  Â  # Extract fixed info for local formatting
Â  Â  Â  Â  fixed_info = {
Â  Â  Â  Â  Â  Â  'Latin Name': plant_row['latin_name'],
Â  Â  Â  Â  Â  Â  'Region of Origin': plant_row['origin'],
Â  Â  Â  Â  Â  Â  'Parts Used': plant_row['parts_used'],
Â  Â  Â  Â  Â  Â  'Contraindications': plant_row['contraindications'],
Â  Â  Â  Â  }
Â  Â  Â  Â Â 
Â  Â  Â  Â  return reading_text, fixed_info

Â  Â  def _get_next_reading_part(self) -> str:
Â  Â  Â  Â  """Retrieves and increments the reading part counter."""
Â  Â  Â  Â Â 
Â  Â  Â  Â  if self.current_reading_step < len(self.expanded_readings):
Â  Â  Â  Â  Â  Â  next_part_content = self.expanded_readings[self.current_reading_step]Â 
Â  Â  Â  Â  Â  Â  self.current_reading_step += 1Â 
Â  Â  Â  Â  Â  Â  return next_part_content
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # All parts have been read
Â  Â  Â  Â  Â  Â  self.current_reading_step = 0 # Reset state
Â  Â  Â  Â  Â  Â  self.expanded_readings = []
Â  Â  Â  Â  Â  Â  return f"That concludes the full reading on **{self.current_plant.capitalize()}**. **Ready for the next plant?**"


Â  Â  def _generate_reading(self, user_input: str) -> str:
Â  Â  Â  Â  """Calls the LLM data fetcher and formats the first part of the reading."""
Â  Â  Â  Â Â 
Â  Â  Â  Â  narrative, fixed_info = self._get_expanded_reading(user_input)

Â  Â  Â  Â  # Build the formatted response with fixed info
Â  Â  Â  Â  response = ""
Â  Â  Â  Â  response += f"***\n"
Â  Â  Â  Â  response += f"**Latin Name:** {fixed_info.get('Latin Name', 'N/A')} | "
Â  Â  Â  Â  response += f"**Region:** {fixed_info.get('Region of Origin', 'N/A')} | "
Â  Â  Â  Â  response += f"**Parts Used:** {fixed_info.get('Parts Used', 'N/A')}\n"
Â  Â  Â  Â  response += f"***\n\n"

Â  Â  Â  Â  # Check if an error occurred during expansion
Â  Â  Â  Â  if "[LLM STRUCTURE ERROR]" in narrative:
Â  Â  Â  Â  Â  Â  response += narrative
Â  Â  Â  Â  Â  Â  response += "\n\n**Please try another command or quit.**"
Â  Â  Â  Â  Â  Â  return response

Â  Â  Â  Â  # If successful, format the first part
Â  Â  Â  Â  response += f"**[Expanded Reading Part 1/3 - {self.current_voice.upper()} Persona]**\n"
Â  Â  Â  Â  response += narrative
Â  Â  Â  Â Â 
Â  Â  Â  Â  # We now ask for the NEXT reading.
Â  Â  Â  Â  if len(self.expanded_readings) > 1:
Â  Â  Â  Â  Â  Â  response += "\n\n**Continue reading this plant's story?**"
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â response += "\n\n**Ready for the next plant?**"
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  return response

Â  Â  # --- VOICE SELECTION ---
Â  Â  def _handle_select_voice(self, user_input: str) -> str:
Â  Â  Â  Â  """Sets the voice, resets step counter, and then performs a reading."""
Â  Â  Â  Â Â 
Â  Â  Â  Â  new_voice = next((v for v in self.voice_options if v in user_input.lower()), None)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if not new_voice:
Â  Â  Â  Â  Â  Â  # Since the LLM handles interpretation, any non-voice command is treated as a redirect/question
Â  Â  Â  Â  Â  Â  return self._handle_redirect(user_input)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  # Reset reading state whenever voice or plant changes
Â  Â  Â  Â  self.current_reading_step = 0
Â  Â  Â  Â  self.expanded_readings = []Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  # The LLM prompt is now responsible for incorporating the user's conversational intent
Â  Â  Â  Â Â 
Â  Â  Â  Â  if self.current_voice is None:
Â  Â  Â  Â  Â  Â  self.current_voice = new_voice
Â  Â  Â  Â  Â  Â  return f"Great choice! I'm excited to share our garden with you from the perspective of a **{new_voice}** herbalist. Let's begin with **{self.current_plant.capitalize()}**.\n\n" + self._generate_reading(user_input)
Â  Â  Â  Â Â 
Â  Â  Â  Â  elif new_voice != self.current_voice:
Â  Â  Â  Â  Â  Â  self.current_voice = new_voice
Â  Â  Â  Â  Â  Â  return f"Voice switched to **{new_voice.upper()}** persona. Here is the expanded note on **{self.current_plant.capitalize()}**:\n\n" + self._generate_reading(user_input)
Â  Â  Â  Â Â 
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # If same voice is selected, regenerate the reading for the current plant (or continue if reading is active)
Â  Â  Â  Â  Â  Â  if self.current_reading_step == 0:
Â  Â  Â  Â  Â  Â  Â  Â  return f"The voice is already set to **{self.current_voice}**. Let's start the reading on **{self.current_plant.capitalize()}**.\n\n" + self._generate_reading(user_input)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  return self._handle_continue_reading(user_input)


Â  Â  # --- NAVIGATION ---
Â  Â  def _handle_plant_navigation(self, user_input: str) -> str:
Â  Â  Â  Â  """Handles 'next plant' or 'plant by name', and then performs a reading."""
Â  Â  Â  Â Â 
Â  Â  Â  Â  if self.current_voice is None:
Â  Â  Â  Â  Â  Â  return f"Please select your preferred herbalist persona: {', '.join(self.voice_options)}."

Â  Â  Â  Â  # 1. Check for 'next reading' command
Â  Â  Â  Â  if self.current_reading_step > 0 and any(w in user_input.lower() for w in ["next reading", "continue", "tell me more"]):
Â  Â  Â  Â  Â  Â  return self._handle_continue_reading(user_input)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  # 2. Check for 'next plant'
Â  Â  Â  Â  if "next plant" in user_input.lower():
Â  Â  Â  Â  Â  Â  if self.current_plant_index == len(self.plant_sequence) - 1:
Â  Â  Â  Â  Â  Â  Â  Â  return "We've completed the tour of all 10 plants. Please select a plant by name if you wish to re-visit one."
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Reset reading state when moving to a new plant
Â  Â  Â  Â  Â  Â  self.current_reading_step = 0Â 
Â  Â  Â  Â  Â  Â  self.expanded_readings = []
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  self.current_plant_index = (self.current_plant_index + 1) % len(self.plant_sequence)
Â  Â  Â  Â  Â  Â  self.current_plant = self.plant_sequence[self.current_plant_index]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  return f"Moving to the next plant, **{self.current_plant.capitalize()}**.\n\n" + self._generate_reading(user_input)

Â  Â  Â  Â  # 3. Check for 'plant by name'
Â  Â  Â  Â  named_plant = next((p for p in self.plant_sequence if p in user_input.lower()), None)
Â  Â  Â  Â  if named_plant:
Â  Â  Â  Â  Â  Â  # Reset reading state when switching to a named plant
Â  Â  Â  Â  Â  Â  self.current_reading_step = 0
Â  Â  Â  Â  Â  Â  self.expanded_readings = []

Â  Â  Â  Â  Â  Â  self.current_plant = named_plant
Â  Â  Â  Â  Â  Â  self.current_plant_index = self.plant_sequence.index(named_plant)
Â  Â  Â  Â  Â  Â  return f"Switching focus to **{self.current_plant.capitalize()}**.\n\n" + self._generate_reading(user_input)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # If input was not a recognized command, it's a redirect.
Â  Â  Â  Â  return self._handle_redirect(user_input)


Â  Â  def _handle_continue_reading(self, user_input: str) -> str:
Â  Â  Â  Â  """Retrieves and formats the next part of the expanded reading."""
Â  Â  Â  Â Â 
Â  Â  Â  Â  # If no reading is active, assume the user is asking a general question about the current plant
Â  Â  Â  Â  if not self.expanded_readings or self.current_reading_step == 0:
Â  Â  Â  Â  Â  Â  return self._generate_reading(user_input)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Retrieve the next part of the story
Â  Â  Â  Â  next_reading = self._get_next_reading_part()
Â  Â  Â  Â Â 
Â  Â  Â  Â  if self.current_reading_step == 0:
Â  Â  Â  Â  Â  Â  return next_reading # Returns the "That concludes the full reading..." message

Â  Â  Â  Â  response = f"**[Expanded Reading Part {self.current_reading_step}/3 - {self.current_voice.upper()} Persona]**\n"
Â  Â  Â  Â  response += next_reading
Â  Â  Â  Â Â 
Â  Â  Â  Â  if self.current_reading_step < 3:
Â  Â  Â  Â  Â  Â  response += "\n\n**Continue reading this plant's story?**"
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  response += "\n\nThat concludes the full reading on this plant. **Ready for the next plant?**"
Â  Â  Â  Â  Â  Â  self.current_reading_step = 0Â 
Â  Â  Â  Â  Â  Â  self.expanded_readings = []
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  return response

Â  Â  def _handle_redirect(self, user_input: str) -> str:
Â  Â  Â  Â  """
Â  Â  Â  Â  Handles inputs that are not clear navigation or voice commands.Â 
Â  Â  Â  Â  Triggers a new reading but allows the LLM to interpret the user's question first.
Â  Â  Â  Â  """
Â  Â  Â  Â  if self.current_voice is None:
Â  Â  Â  Â  Â  Â  return f"Welcome! Please select your preferred herbalist persona: {', '.join(self.voice_options)}."

Â  Â  Â  Â  # Any conversational input that isn't a direct command is treated as a question about the current plant.
Â  Â  Â  Â  # This forces the LLM to process it (e.g., "what's the weather") and redirect, then deliver the script.
Â  Â  Â  Â  return self._generate_reading(user_input)


Â  Â  def respond(self, user_input: str) -> str:
Â  Â  Â  Â  """The main interaction method that executes the logic."""
Â  Â  Â  Â  user_input_lower = user_input.lower().strip()

Â  Â  Â  Â  # 0. Initial Greeting / Persona Selection Prompt
Â  Â  Â  Â  if self.current_voice is None:
Â  Â  Â  Â  Â  Â  if any(v in user_input_lower for v in self.voice_options):
Â  Â  Â  Â  Â  Â  Â  Â  return self._handle_select_voice(user_input)
Â  Â  Â  Â  Â  Â  return f"Welcome! Please select your preferred herbalist persona: {', '.join(self.voice_options)}."


Â  Â  Â  Â  # 1. COMMAND: Continue Reading (High Priority)
Â  Â  Â  Â  if self.current_reading_step > 0 and any(w in user_input_lower for w in ["continue", "next reading", "more", "tell me more"]):
Â  Â  Â  Â  Â  Â  return self._handle_continue_reading(user_input)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 2. COMMAND: Change VoiceÂ 
Â  Â  Â  Â  if any(v in user_input_lower for v in self.voice_options):
Â  Â  Â  Â  Â  Â  return self._handle_select_voice(user_input)

Â  Â  Â  Â  # 3. COMMAND: Next Plant or Plant by NameÂ 
Â  Â  Â  Â  plant_commands = ["next plant"] + self.plant_sequence
Â  Â  Â  Â  if any(p in user_input_lower for p in plant_commands):
Â  Â  Â  Â  Â  Â  return self._handle_plant_navigation(user_input)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 4. Handle all other inputs (Redirect/Vague Question)
Â  Â  Â  Â  # This now routes ALL conversational inputs back to _generate_readingÂ 
Â  Â  Â  Â  # via _handle_redirect, allowing the LLM prompt to manage the guardrail and content delivery.
Â  Â  Â  Â  return self._handle_redirect(user_input)

# ======================================================================
# 5. API INTERACTION FUNCTION
# ======================================================================

def generate_llm_response(system_prompt_content: str) -> str:
Â  Â  """Sends the system prompt to the chosen LLM for prose generation (structured expansion)."""
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  response = client.chat.completions.create(
Â  Â  Â  Â  Â  Â  model=MODEL_ID,
Â  Â  Â  Â  Â  Â  messages=[
Â  Â  Â  Â  Â  Â  Â  Â  {"role": "system", "content": system_prompt_content},
Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  temperature=0.5,Â 
Â  Â  Â  Â  Â  Â  max_tokens=1024Â 
Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Log success (only visible in Streamlit Cloud logs)
Â  Â  Â  Â  print(f"DEBUG A: LLM API call SUCCESS.")Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  raw_content = response.choices[0].message.content
Â  Â  Â  Â Â 
Â  Â  Â  Â  # --- FAIL-SAFE CHECK ---
Â  Â  Â  Â  if not raw_content or raw_content.isspace():
Â  Â  Â  Â  Â  Â  print(f"[LLM CONTENT FAIL] Model returned empty or blank content for prompt.")
Â  Â  Â  Â  Â  Â  return "[EMPTY CONTENT ERROR] The LLM returned a blank response."
Â  Â  Â  Â  # ---------------------------

Â  Â  Â  Â  # Return the raw content
Â  Â  Â  Â  return raw_content
Â  Â  Â  Â Â 
Â  Â  except Exception as e:
Â  Â  Â  Â  # Critical failure if the LLM can't generate the reading
Â  Â  Â  Â  print(f"\n[CRITICAL LLM ERROR] Failed to expand reading: {type(e).__name__} - {e}")
Â  Â  Â  Â  return f"[CRITICAL LLM ERROR] Failed to expand reading: {type(e).__name__} - {e}"

# ======================================================================
# 6. STREAMLIT UI RUNNER
# ======================================================================

def run_streamlit_app():
Â  Â  # 1. Configuration and Title
Â  Â  st.set_page_config(page_title="Botanical Guide Agent", layout="centered")
Â  Â  st.title("ðŸŒ¿ Interactive Botanical Guide")
Â  Â  st.markdown("---")
Â  Â Â 
Â  Â  # 2. API Key Loading (using Streamlit's secrets for security)
Â  Â  try:
Â  Â  Â  Â  openrouter_key = st.secrets["OPENROUTER_API_KEY"]
Â  Â  except KeyError:
Â  Â  Â  Â  st.error("API Key not found in Streamlit Secrets. Please configure `OPENROUTER_API_KEY`.")
Â  Â  Â  Â  return

Â  Â  # 3. Initialization and Agent SetupÂ 
Â  Â  if 'agent' not in st.session_state:
Â  Â  Â  Â Â 
Â  Â  Â  Â  # CRITICAL: Initialize the global client with the loaded secret
Â  Â  Â  Â  global clientÂ 
Â  Â  Â  Â  client = OpenAI(
Â  Â  Â  Â  Â  Â  base_url="https://openrouter.ai/api/v1",
Â  Â  Â  Â  Â  Â  api_key=openrouter_key,Â 
            # 2. ADDED: Increased request timeout to handle complex generation
            timeout=httpx.Timeout(120.0, connect=30.0) 
Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Initialize the rest of the agent's state
Â  Â  Â  Â  PLANT_DATA = load_and_structure_plant_data(DOC_TEXT, PLANT_SEQUENCE, VOICE_MAPPING)
Â  Â  Â  Â  st.session_state.agent = BotanicalGuideAgent(PLANT_DATA, PLANT_SEQUENCE, VOICE_OPTIONS)
Â  Â  Â  Â  st.session_state.messages = []
Â  Â  Â  Â  st.session_state.messages.append(
Â  Â  Â  Â  Â  Â  {"role": "agent", "content": st.session_state.agent.respond("")}
Â  Â  Â  Â  )

Â  Â  # 4. Display Chat History
Â  Â  for message in st.session_state.messages:
Â  Â  Â  Â  with st.chat_message(message["role"]):
Â  Â  Â  Â  Â  Â  st.markdown(message["content"])

Â  Â  # 5. Handle User Input
Â  Â  if prompt := st.chat_input("Enter your command (e.g., 'elder', 'continue', 'next plant', 'ginger')..."):
Â  Â  Â  Â  # Add user prompt to history
Â  Â  Â  Â  st.session_state.messages.append({"role": "user", "content": prompt})
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Display user message immediately
Â  Â  Â  Â  with st.chat_message("user"):
Â  Â  Â  Â  Â  Â  st.markdown(prompt)

Â  Â  Â  Â  # Get agent response
Â  Â  Â  Â  with st.chat_message("agent"):
Â  Â  Â  Â  Â  Â  # The agent's respond method handles all the logic and LLM calls
Â  Â  Â  Â  Â  Â  response = st.session_state.agent.respond(prompt)
Â  Â  Â  Â  Â  Â  st.markdown(response)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Update history with agent's response
Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "agent", "content": response})

# Run the app function when the script starts
if __name__ == "__main__":
Â  Â  run_streamlit_app()
